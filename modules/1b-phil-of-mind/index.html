<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/nlpwme/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/nlpwme/css/franklin.css"> <link rel=stylesheet  href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css"> <link rel=stylesheet  href="/nlpwme/css/font-awesome.min.css"> <link rel=stylesheet  href="/nlpwme/css/celeste.min.css"> <link rel=icon  type="image/png" sizes=200x200  href="/nlpwme/assets/robot.png"> <link rel=apple-touch-icon-precomposed  sizes=152x152  href="/nlpwme/assets/apple-touch-icon.png"> <title>NLPwShiyi - Natural Language Processing with Shiyi</title> <nav id=navbar  class=navigation  role=navigation > <input id=toggle1  type=checkbox  /> <label class=hamburger1  for=toggle1 > <div class=top ></div> <div class=meat ></div> <div class=bottom ></div> </label> <nav class="topnav mx-auto" id=myTopnav > <div class=dropdown > <button class=dropbtn >Comp Ling <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/1a-info-theory">Information Theory</a> <a href="/nlpwme/modules/1b-phil-of-mind">Philosophy of Mind</a> <a href="/nlpwme/modules/1c-noisy-channel-model">The Noisy Channel Model</a> <a href="/nlpwme/modules/1d-finite-automata">FSAs and FSTs</a> <a href="/nlpwme/modules/1e-mutual-info">Mutual Information</a> <a href="/nlpwme/modules/1f-cky-algorithm">CKY Algorithm</a> <a href="/nlpwme/modules/1g-viterbi">Viterbi Algorithm</a> <a href="/nlpwme/modules/1h-semantics">Logic and Problem Solving</a> <a href="/nlpwme/modules/1i-cryptanalysis">Cryptography</a> </div> </div> <div class=dropdown > <button class=dropbtn  >DL / NLP <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/2a-mdn-nlp">Modern NLP</a> <a href="/nlpwme/modules/2b-markov-processes">Markov Processes</a> <a href="/nlpwme/modules/2c-word2vec">Word2Vec</a> <a href="/nlpwme/modules/2e-jax">Jacobian Matrices Derivation</a> <a href="/nlpwme/modules/2d-automatic-differentiation">Automatic Differentiation</a> <a href="/nlpwme/modules/2f-loss-functions">Stochastic GD</a> <a href="/nlpwme/modules/2g-batchnorm">Batchnorm</a> <a href="/nlpwme/modules/2j-perplexity">Perplexity</a> <a href="/nlpwme/modules/2h-dropout">Dropout</a> <a href="/nlpwme/modules/2i-depth">Depth: Pros and Cons</a> <a href="/nlpwme/modules/2k-VAE">Variational Autoencoders</a> <a href="/nlpwme/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a> </div> </div> <a href="/nlpwme/" class=active >Intro </a> <div class=dropdown > <button class=dropbtn  >SOTA <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a> <a href="/nlpwme/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a> <a href="/nlpwme/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a> <a href="/nlpwme/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a> <a href="/nlpwme/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a> </div> </div> <div class=dropdown > <button class=dropbtn  >Hands-on <i class="fa fa-caret-down"></i> </button> <div class=dropdown-content > <a href="/nlpwme/modules/4a-mlp-from-scratch">MLP from Scratch</a> <a href="/nlpwme/modules/4b-generative-adversarial-networks">GAN Example </a> <a href="/nlpwme/modules/4c-vae-mnist">VAE for MNIST</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">BI-LSTM-CRF S2S</a> <a href="/nlpwme/modules/4d-bi-lstm-crf">OCR Handwriting Recognition</a> <a href="/nlpwme/modules/4e-c4fe-tbip">Text-based Ideal Points Model</a> <a href="/nlpwme/modules/4f-etl-job">DE: Serverless ETL</a> <a href="/nlpwme/modules/4f-etl-job">PySpark SQL Example</a> </div> </div> </nav> </nav> <div class=franklin-content ><h1 id=what_constitutes_as_the_philosophy_of_mind ><a href="#what_constitutes_as_the_philosophy_of_mind" class=header-anchor >What Constitutes As The Philosophy of Mind？</a></h1> <p>This blog will summarize articles, papers, and material I have gone through that touch on the subject of <em>The Computational Theory of Mind</em>.</p> <p>In this one article that touches on this subject, it&#39;s known that the computational theory of mind promises us the abilities of a machine to emulate reasoning, decision-making, problem solving, perception, linguistic comprehension, and other mental processes.</p> <p><strong>Table Of Contents</strong></p> <div class=franklin-toc ><ol><li><a href="#the_implications_of_human_beings_as_conscious_automata_and_the_definition_of_consciousness">The Implications of Human Beings As Conscious Automata and The Definition of Consciousness</a><ol><li><a href="#consciousness_as_the_fundamental_property_of_nature">Consciousness As The Fundamental Property of Nature</a><li><a href="#consciousness_as_weakstrongnormal_emergence">Consciousness As Weak/Strong/Normal Emergence</a><li><a href="#the_primal_instincts_vs_the_unknown">The Primal Instincts vs. The Unknown</a><ol><li><a href="#so_what_does_it_mean_by_having_conscious_thoughts_in_a_purely_physicalmaterialistic_sense">So What Does It Mean By Having Conscious Thoughts in A Purely Physical/Materialistic Sense?</a></ol><li><a href="#logical_behaviorism_vs_typetoken-identity_theory">Logical Behaviorism vs Type/Token-Identity Theory</a></ol><li><a href="#computationalism_and_the_classical_computational_theory_of_mind">Computationalism and The Classical Computational Theory of Mind</a><ol><li><a href="#a_turing_style_computational_system">A Turing Style Computational System</a></ol><li><a href="#the_classical_computational_vs_the_representational_theory_of_mind">The Classical Computational vs The Representational Theory of Mind</a><ol><li><a href="#computationalism_vs_functionalism">Computationalism vs Functionalism</a><li><a href="#the_functionality_and_usability_of_affective_values">The Functionality and Usability of Affective Values</a></ol><li><a href="#tying_everything_together_and_connecting_the_dots">Tying Everything Together and Connecting The Dots</a></ol></div> <h3 id=the_implications_of_human_beings_as_conscious_automata_and_the_definition_of_consciousness ><a href="#the_implications_of_human_beings_as_conscious_automata_and_the_definition_of_consciousness" class=header-anchor >The Implications of Human Beings As Conscious Automata and The Definition of Consciousness</a></h3> <p>Advances in computing raise the prospect known as <em>The Computational Theory of Mind</em> &#40;CTM&#41;. Computationalists understand this paradigm as the principle to cognitive science. Then later two schools of thoughts challenged this orthodox position.</p> <p>One pertains to the neurological properties of the mind and body and the other emphasized representational mental states. To have a better understanding overall, we have to first know where these premises in the realm of CTM stemmed from. Below are some very important and relevant theories in Cognitive Science.</p> <h4 id=consciousness_as_the_fundamental_property_of_nature ><a href="#consciousness_as_the_fundamental_property_of_nature" class=header-anchor >Consciousness As The Fundamental Property of Nature</a></h4> <p>Everything started from the debate about what consciousness and mental representations really are, and it has been going on for centuries.</p> <p>In answering the question of why we need consciousness, one of the proposed answers is that consciousness is a fundamental property of nature. It&#39;s added that,</p> <pre><code class="plaintext hljs">“We know that a theory of consciousness requires the addition of 
something fundamental to our ontology, as everything in physical 
theory is compatible with the absence of consciousness.

We might add some entirely new nonphysical feature, from which 
experience can be derived […] we will take experience itself as 
a fundamental feature of the world, alongside mass, charge, and 
space-time”.</code></pre> <p>This is also known as &quot;fundamental property dualism&quot;, which, in David Chalmers&#39; definition, <code>&quot;regards conscious mental properties as basic constituents of reality on a par with fundamental physical properties such as electromagnetic charge. They may interact in casual and lay-like ways with other fundamental properties such as those of physics, but ontologically their existence is not dependent upon nor derivative from any other properties&quot;.</code></p> <p>According to this <a href="https://medium.com/curious/are-we-conscious-automata-18ba889af20">medium article</a>, this idea is also referred to as panpsychism, which &quot;holds that mind or a mind-like aspect is a fundamental and ubiquitous feature of reality&quot;. It is also described as a theory that &quot;the mind is a fundamental feature of the world which exists throughout the universe.&quot;</p> <h4 id=consciousness_as_weakstrongnormal_emergence ><a href="#consciousness_as_weakstrongnormal_emergence" class=header-anchor >Consciousness As Weak/Strong/Normal Emergence</a></h4> <p>Each one of them is a hypothesis over the emergence and origin of consciousness, and below is a more detailed breakdown.</p> <div class=colbox-blue ><p><strong>Strong Emergence</strong>: This is the position that is too good to be true and therefore argued against. As it&#39;s not very much plausible that it&#39;s the downward causal direction, where the emergence of consciousness caused the microscopic and molecular changes happening at a lower-level. </p> <p>The only justification to this position is that it opens up possibilities for free will, explained by the physicist Sean Carroll.</p> <p>Downward causation is one manifestation of this strong-emergence attitude. It’s the idea that what happens at lower levels can be directly influenced &#40;causally acted upon&#41; by what is happening at the higher levels. </p> <p>The idea, in other words, that you can’t really understand the microscopic behavior without knowing something about the macroscopic.</p> <p><strong>Weak Emergence</strong>: Instead of being a strong emergence, maybe in reality consciousness might just be a weak emergence instead as proposed.</p> <p>The so-called “weak” emergence suggests that higher-level notions like the fluidity or solidity of a material substance emerge out of the properties of its microscopic constituents. </p> <p>In principle, if not in practice, the microscopic description is absolutely complete and comprehensive. A “strong” form of emergence would suggest that something truly new comes into being at the higher levels, something that just isn’t there in the microscopic description.</p> <p>The example used was when we talk about atoms and other physical properties, it might not be suitable to talk about free will, but under the philosophical discussions about human consciousness, motivation, and behavior, it may be otherwise.</p></div> <p>ℹ️ In such case, explaining what a weak emergence is, we may ask the question: if we take the view that consciousness does affect our thoughts and behavior, is that view applicable at the level of atoms and particles, or only at the level appropriate for describing human psychology?</p> <pre><code class="plaintext hljs">In answering this question, the article used a different analogy; 
consider the mechanism that regulates the constriction and 
dilation of our pupils according to the intensity of the 
light reaching them. 

We could say that there&#x27;s a sort of sensor in our eyes or in our 
visual processing area in the brain that causes our pupils to 
behave that way, yet at the fundamental level of physics, the 
knowledge of such a sensory mechanism is not needed to predict 
(in principle) the behavior of all the particles composing the 
eye as they interact among themselves and with all the external 
particles affecting them. 

Still, we wouldn&#x27;t say that the sensor is merely a byproduct 
that accomplishes nothing.</code></pre> <p>Therefore, instead of agreeing on each extreme end of the spectrum, below might help construe and reach the ultimate conclusion.</p> <div class=colbox-blue ><p><strong>Normal Emergence</strong>: The visual sensor is obviously affecting the behavior of the pupil, yet it doesn&#39;t follow that it&#39;s affecting the behavior of the underlying atoms in a way that contradicts or is incompatible with our understanding of how atoms behave.</p> <p>Without the sensor, the atoms wouldn&#39;t behave as they do, and in that sense the sensor is necessary for the pupil to constrict and dilate; it&#39;s that it&#39;s necessary to know the existence of the sensor to predict what the atoms of the eye will do next.</p> <p>In the domain that deals with how the eye works, it&#39;s useful and practical to speak of some sort of sensory mechanism; in the domain that deals with how atoms behave, it isn&#39;t - it isn&#39;t even necessary. Perhaps we could understand consciousness in the same way.</p></div> <h4 id=the_primal_instincts_vs_the_unknown ><a href="#the_primal_instincts_vs_the_unknown" class=header-anchor >The Primal Instincts vs. The Unknown</a></h4> <p>However, it seems though the importance of consciousness might have been overall exaggerated. A few primal physical responses of humans have indicated that humans could task being an automata without these familiar yet mysterious qualia. </p> <p>For example, humans could drive while talk, have fight-and-flight responses without being aware of it, and blindsight which are sensational responses to visual stimuli without actually experiencing the effects visually.</p> <p>Lastly, onto the discussions about pain. It seems that the presence of pain is superfluous. We need not to have to experience pain to understand the risk of injury and be avoidance of danger.</p> <p>According to a prominent English biologist Thomas Henry Huxley &#40;1825-1895&#41;, he believed that sensations and feelings are mere byproduct of mechanics of the brain. An epiphenomenon that is not the cause of any behavior. In his essay, &quot;On the Hypothesis that Animals Are Automata, and Its History&quot; he wrote:</p> <div class=colbox-blue ><h5 id=so_what_does_it_mean_by_having_conscious_thoughts_in_a_purely_physicalmaterialistic_sense ><a href="#so_what_does_it_mean_by_having_conscious_thoughts_in_a_purely_physicalmaterialistic_sense" class=header-anchor >So What Does It Mean By Having Conscious Thoughts in A Purely Physical/Materialistic Sense?</a></h5> <p>The consciousness of brutes would appear to be related to the mechanism of their body simply as a collateral product of its working, and to be as completely without any power of modifying that working as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery.</p> <p><em>Their volition, if they have any, is an emotion indicative of physical changes, not a cause of such changes. &#91;…&#93;</em></p> <p>It is quite true that, to the best of my judgment, the argumentation which applies to brutes holds equally good of men; and, therefore, that all states of consciousness in us, as in them, are immediately caused by molecular changes of the brain-substance. It seems to me that in men, as in brutes, there is no proof that any state of consciousness is the cause of change in the motion of the matter of the organism.</p></div> <p>In the same light, this other, in the paper &quot;The &#39;Mental&#39; and the &#39;Physical&#39;&quot;, this other re-known philosopher J.J.C. Smart &#40;crediting the term to Herbert Feigl&#41; presented his theories about &#39;is consciousness a brain process?&quot;</p> <p>He argues a position coined as the &quot;Nomological dangler&quot; about &quot;Sensations and Brain Processes&quot;, which refers to the occurrences of something that does not fit into the system of established laws.</p> <p>He argues against the dualists&#39; and <a href="https://en.wikipedia.org/wiki/Epiphenomenalism">epiphenomenalism</a>&#39;s position on the dichotomy between mind-body and for a monistic view or interchangeably physicalism where the mind is a product of or identical to physical processes, stating that according to Occam&#39;s razor seeing a mental process like consciousness as purely physical gets rid of the hassle of not having been able to explain the grey area of what these brain processes actually are in a more scientific and established system.</p> <p>To quote him more specifically,</p> <pre><code class="plaintext hljs">It was believed that it is absurd that everything can be explained 
by the laws of physics except consciousness. In this case, he 
identifies consciousness with the broad term &quot;sensations&quot;.</code></pre> <p>Below summarizes scientific approaches and proposals that tackle the mind-body/consciousness problem that reflect the two distinct assumptions explained above,</p> <div class=colbox-blue ><h5 id=logical_behaviorism_vs_typetoken-identity_theory ><a href="#logical_behaviorism_vs_typetoken-identity_theory" class=header-anchor >Logical Behaviorism vs Type/Token-Identity Theory</a></h5> <p>Logical behaviorism holds that all thoughts, perceptions, and other mental processes can be classified in the same way that mathematics can be explained in terms of formal logic, using concepts like set theory, and can then be <strong>tested and scientifically explained using behaviorist principles</strong>, according to which everything is made up of <strong>stimulus-response</strong> pairs with various types of origins and reinforcement.</p> <p>According to type/token-identity theory, the experience of something is considered to be a brain process that is occurring not merely as a mental state. Identity theorists additionally contend that brain states are just <strong>physical</strong>, which contradicts the irreducible non-physical aspects known as &quot;qualia&quot; of the brain, such as desires and beliefs.</p> <p>In short,</p> <ul> <li><p>Logical behaviorism focuses on the relationship between mental states and observable behavior or external responses &#40;behaviorism&#41; and is more aligned with mind-body dualism.</p> <li><p>Type/token identity theory focuses on the relationship between mental states and physical states of the brain and is more aligned with physicalism or materialism.</p> </ul></div> <p>The second of the two very important approaches in Cognitive Science helped serve as the foundation for creating the predecessor intelligent systems of the AI we see today.</p> <h3 id=computationalism_and_the_classical_computational_theory_of_mind ><a href="#computationalism_and_the_classical_computational_theory_of_mind" class=header-anchor >Computationalism and The Classical Computational Theory of Mind</a></h3> <p>In a similar light, CCTM or the Classical Computational Theory of Mind was established without addressing the qualitative or subjective aspects of mental processes.</p> <p>According to CCTM, the mind is a computational system similar in important respects to a Turing machine, and core mental processes &#40;e.g., reasoning, decision-making, and problem solving&#41; are computations similar in important respects to computations executed by a Turing machine.</p> <p>First, CCTM is better formulated by describing the mind as a “computing system” or a “computational system” rather than a “computer”. As David Chalmers - an Australian philosopher and cognitive scientist specializing in the areas of philosophy of mind and philosophy of language - &#40;2011&#41; notes, describing a system as a “computer” strongly suggests that the system is programmable. As Chalmers also notes, one need not claim that the mind is programmable simply because one regards it as a Turing-style computational system.</p> <p>Second, CCTM is not intended metaphorically. CCTM does not simply hold that the mind is like a computing system. CCTM holds that the mind <code>literally is a computing system</code>. The most familiar artificial computing systems are made from silicon chips or similar materials, whereas the human body is made from flesh and blood. But CCTM holds that this difference disguises a more fundamental similarity, which we can capture through a Turing-style computational model.</p> <div class=colbox-blue ><h4 id=a_turing_style_computational_system ><a href="#a_turing_style_computational_system" class=header-anchor >A Turing Style Computational System</a></h4> <ul> <li><p>memory locations: assuming an infinitely long linear structure or system, here is where these symbols might be kept. &#40;In real life scenarios, there are always ways to optimize memory locations and storage space, including through the use of techniques like hashing, because the implementation could not realistically assume infinity&#41;.</p> <li><p>a central processor, which has a limited number of machine states it can enter.</p> <li><p>The central processor&#39;s basic actions on symbols include writing and deleting symbols as well as accessing the next memory position in the linear array. &#40;On the tape, veer to the left or right&#41;.</p> <li><p>two key principles are used in the operation to process the data: the current symbol that is stored at the current memory address, and the scanner&#39;s own current machine state.</p> <li><p>a machine table, which, based on the central processor&#39;s present machine state and the symbol it is currently accessing, determines which elementary operation it will carry out. It also determines how those same circumstances affect the machine state of the central processor.</p> <li><p>human cognitive constraints - lastly, the symbolic system that the Turing computer symbolizes could effectively duplicate it due to our cognitive constraints, which can only yield a certain number of possibilities.</p> </ul></div> <p>One important breakthrough invention during the computationalism era was the <em>Logic Theorist</em> computer program &#40;Newell and Simon 1956&#41; which proved 38 of the first 52 theorems from <em>Principia Mathematica</em> &#40;Whitehead and Russell 1925&#41;.</p> <p>Since the discrete nature of the system, it&#39;s concerned with its competency of whether it could model the continuous nature of human cognition. There&#39;s between the <em>digital</em> paradigm behind the system with <em>analog</em> system.</p> <p>The Turing machine also proved the existence of a <em>Universal Turing Machine</em> &#40;UTM&#41;, which results in the ultimate development of current computer logic and system. More importantly, a personal computer can mimic any Turing machine <em>until it exhausts its limited memory supply</em>.</p> <h3 id=the_classical_computational_vs_the_representational_theory_of_mind ><a href="#the_classical_computational_vs_the_representational_theory_of_mind" class=header-anchor >The Classical Computational vs The Representational Theory of Mind</a></h3> <p>As opposed to type-identity theory, where mental states are brain states, Putnam proposed a different view that mental states are <a href="https://plato.stanford.edu/entries/multiple-realizability/"><em>multiply realizable</em></a>: the same mental state can be realized by diverse physical systems, including not only terrestrial creatures but also hypothetical creatures.</p> <pre><code class="julia hljs">Functionalism therefore is tailor-made to accommodate multiple 
realizability.</code></pre> <p>He stresses the importance of <em>probabilistic automata</em>, stating that mental states are the machine states of the automaton&#39;s central processor.</p> <p>In summary, functionalism was introduced to address the functional aspects of mental processes &#40;the functional role of an automaton&#39;s central processor; for example to manipulate symbols&#41;; the computational theory of mind provides a computational framework to describe such a process &#40;namely the process of manipulating symbols by the central process is considered as a mental process being &quot;computational&quot; &#41;.</p> <p>Lastly, the type/token-identity theory or physicalism of our cognitive processes defines that similar to a natural language &#40;where a CAT is a type and every appearing instance of the word CAT is a token&#41; defines the mental representations that central processor is able to manipulate, operate on, and make computations/calculations with.</p> <h4 id=computationalism_vs_functionalism ><a href="#computationalism_vs_functionalism" class=header-anchor >Computationalism vs Functionalism</a></h4> <p>In offering such a model, we prescind from physical details. We attain an abstract computational description that could be physically implemented in diverse ways &#40;e.g., through silicon chips, or neurons, or pulleys and levers&#41;. CCTM holds that a <code>suitable abstract computational model offers a literally true description of core mental processes</code>.</p> <pre><code class="julia hljs">As per definition, the mind is the functional organization 
of the brain, whereas computationalism argues that the functional organization of the brain is computable so namely
the mind is computable.</code></pre> <p>However, this line of thinking imposed a serious challenge on the early development of AI and nearly sent the field into a dead end and a period of stagnation called the winter period. The weakness of this thought lies in the fact that human cognition has limitations and couldn&#39;t entertain infinite amount of propositions and rules, which entails that it reflects poorly the productivity of these mental processes. On top of that there are some other major limitations,</p> <blockquote> <p><strong>Symbol Grounding Problem</strong>: CTM struggles to explain how abstract symbols in the mind acquire meaning. It doesn&#39;t account for how symbols connect to the external world.</p> </blockquote> <blockquote> <p><strong>Qualia and Consciousness</strong>: CTM has difficulty explaining subjective experiences &#40;qualia&#41; and consciousness. It tends to focus on functional aspects without addressing the qualitative nature of mental states.</p> </blockquote> <blockquote> <p><strong>Flexibility and Adaptability</strong>: CTM often assumes rigid rule-based processing, which may not fully capture the flexible and adaptive nature of human cognition.</p> </blockquote> <p>Coming back to the important discussion around consciousness. Now we could ask that,</p> <p>ℹ️ why isn&#39;t this indication enough for such a phenomenon enough to explain what these &quot;nomologically dangling&quot; ideas? And what exactly is the purpose of and function of consciousness? or the importance of qualia?</p> <p>One answer to the questions argues that they are not merely physical, it&#39;s the nature&#39;s decision bestowed upon us with free will. It lets us to decide with this warning sign. It&#39;s more so a trade-off handed over to our free will. We experience discomfort caused by external stimulation and then we are given the option to consciously decide what we are going to do with it.</p> <p>Another objection to the byproduct hypothesis would be that,</p> <div class=colbox-blue ><h4 id=the_functionality_and_usability_of_affective_values ><a href="#the_functionality_and_usability_of_affective_values" class=header-anchor >The Functionality and Usability of Affective Values</a></h4> <p>If pleasure and discomfort have no consequences, there would seem to be no reason why we couldn&#39;t detest the feelings brought on by necessary actions or relish them when generated by harmful ones.</p> <p>Therefore, if epiphenomenalism were accurate, it would be necessary to provide a special justification for the harmonious relationship between our feelings&#39; affective value and their usefulness in our daily lives. Nevertheless, this alignment could not have a true explanation based on epiphenomenalist presumptions.</p> <p>Affective valuation would not have any behavioral implications if it were misaligned with the usefulness of the causes of the evaluated sensations, and vice versa. Therefore, the felicitous alignment could not be chosen.</p> <p>Epiphenomenalists and physicalists would only be left with the option of accepting a crude and unscientific understanding of the pre-existing harmony of affective appraisal of feelings and the usefulness of their sources.</p></div> <p>Later then came about the renaissance period with the blooming of connectionism grounded in <em>The Representational Theory of Mind</em>. RTM was developed to address these limitations. Not only did it not shy away from the traditional rationalism or symbolicist ideals, it incorporated the aspects and was established to addresses these limitations,</p> <blockquote> <p><strong>Emphasis on Representations</strong>: RTM places a central focus on mental representations, acknowledging that cognitive processes involve manipulating and interpreting these representations.</p> </blockquote> <blockquote> <p><strong>Connection to the External World</strong>: RTM attempts to tackle the Symbol Grounding Problem by emphasizing the connection between mental representations and the external world. It explores how representations acquire meaning through their relationship to real-world objects or events.</p> </blockquote> <blockquote> <p><strong>Integration of Qualitative Aspects</strong>: RTM accommodates the qualitative aspects of consciousness and subjective experiences by acknowledging the role of mental representations in shaping our perception of the world.</p> </blockquote> <blockquote> <p><strong>Flexibility in Cognitive Processing</strong>: RTM allows for more flexibility in cognitive processing by recognizing that mental representations can be dynamic and context-dependent.</p> </blockquote> <p>RTM is able to accomplish the above by assuming,</p> <pre><code class="plaintext hljs">Productivity:

a finites set of symbols in natural language and the 
device could entertain a infinite numbers of logic.

Systematicity:

that there are inherent systematic relations 
between basic cognitive constitutions.</code></pre> <p>More importantly, with a shift in the representation of information toward a sub-symbolic, universally distributed approach. While the specific mention is about solving a philosophical conundrum related to representations of meaning, we can consider how this shift might also address the potential conundrum faced by classicists - the syntactic underpinnings. Here are some ways in which this approach could be relevant:</p> <blockquote> <p><strong>Contextual Integration of Syntax</strong>: The sub-symbolic, universally distributed approach may allow for a more seamless integration of syntactic information within a broader context. Traditional symbolic approaches may struggle with the dynamic and context-dependent nature of syntax, whereas a distributed approach could potentially capture syntactic patterns in relation to the overall semantic and contextual context.</p> </blockquote> <blockquote> <p><strong>Dynamic Syntactic Representations</strong>: Traditional syntactic representations often rely on explicit rules and structures. The sub-symbolic nature of the described approach might enable the system to dynamically adapt its syntactic representations based on contextual demands. This could allow for a more fluid and contextually relevant expression of syntactic structures.</p> </blockquote> <blockquote> <p><strong>Flexible Syntactic Processing</strong>: A sub-symbolic, universally distributed mechanism might be better suited to handle syntactic variations and nuances across different contexts. Instead of relying on rigid syntactic rules, the system could adapt and learn syntactic patterns in a more flexible manner.</p> </blockquote> <blockquote> <p><strong>Capturing Syntactic Ambiguity</strong>: Syntactic structures can sometimes be ambiguous, and their interpretation may depend on the broader context. The described approach may facilitate the capture of syntactic ambiguity by allowing for a distributed representation that considers the surrounding information and context.</p> </blockquote> <blockquote> <p><strong>Learning Syntactic Relationships</strong>: The universally distributed learning mechanism mentioned in the passage suggests a collective learning process across different units. This could potentially allow the system to learn syntactic relationships in a more distributed and collaborative manner, accommodating the complexity of syntactic structures.</p> </blockquote> <p>While the passage doesn&#39;t explicitly mention syntactic underpinnings, the shift toward a sub-symbolic, universally distributed representation seems to open up possibilities for addressing challenges related to syntactic representation and processing. By embracing a more dynamic and contextually adaptive approach, this mechanism may provide a framework for capturing syntactic information in a manner that aligns with the overall goals of the system.</p> <h3 id=tying_everything_together_and_connecting_the_dots ><a href="#tying_everything_together_and_connecting_the_dots" class=header-anchor >Tying Everything Together and Connecting The Dots</a></h3> <p>Philosophers only started to become interested in connectionism because it offers an alternative to the classical computational theory of mind.</p> <pre><code class="plaintext hljs">Connectionism is a movement that has been put out in the field of 
cognitive science in hope to explain and extrapolate the mental 
processes of a brain. It&#x27;s composed of a simplified emulation of 
the actual cognitive compositions of a brain, by having connected 
neurons or units (the analogs of neurons) within which are assigned 
weights that measure how strongly the connections are there between 
units. We could picture these weights as a replica of the synapse 
in our actual biological brain that link one neuron to each other.</code></pre> <p>The bridging between classicist and connectionist view and the departure from it became that a lot of connectionists view cognitive processing as analog as the computer processing as digital.</p> <p>Many connectionists argue that weight units that are dynamic, continuous, and analogous in nature which therefore reflect better the way that human brain processes information through different mental states.</p> <p>On the other hand, classicists view information processing done by humans as similar to a computational system where information is stored symbolically and processed systematically through automatons. And the storing of information is similar to that of a computer where there&#39;s &quot;memory locations&quot; for information access and retrieval.</p> <p>However, many connectionists seek to bridge these two paradigms together instead of trying to argue for one over the other. One of the schools - the implementational connectionists - seeks to find a solution that accommodates these two different hypotheses.</p> <p>It&#39;s also argued by radical connectionists that the traditional or the symbolic way of treating human cognitive information processing should be eliminated because how poorly it reflects these dynamics in human consciousness that could otherwise be materialized through connectionism.</p> <pre><code class="plaintext hljs">Graceful degradation of function, holistic representation 
of data, spontaneous generalization, appreciation of context, etc.</code></pre> <p>Yet, hybrid mechanisms were put out by different teams to mediate such clashes. For example, there were papers that drew inspiration from the classical style of information processing &#40;having one module that acts as the memory location or implementing methods that utilize variable binding techniques for symbolic processing that reflects the classical computational way of thinking aka the turing style information processing and storage&#41;.</p> <pre><code class="plaintext hljs">Also one interesting discovery about the connectionism 
representation of information processing inside the brain 
might have a good give away of how brain actually processes 
information.

That is, instead of a local representation of an individual 
or specific informational unit, the learning mechanism is 
more so universally distributed across different (hidden) units.

To top it off, the new way of representing information&#x27;s 
sub-symbolic nature - where there were no intrinsic properties 
of representations that determine their relationships with 
other symbols - might solve a philosophical conundrum in 
representations of meaning.

In contrast, a distributed representation preserves patterns 
across the net that could allow comparison and good preservation 
when parts go amok.</code></pre> <p>In short, this hybrid architecture might have had a say to how human brains actually process information.</p> <p><strong>References</strong></p> <p><em>Rescorla, Michael, &quot;The Computational Theory of Mind&quot;, The Stanford Encyclopedia of Philosophy &#40;Fall 2020 Edition&#41;, Edward N. Zalta &#40;ed.&#41;</em></p> <div class=page-foot > <div class=copyright > <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class=github-logo  src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></b></a> ©️ Last modified: March 28, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/nlpwme/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>