<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/libs/katex/katex.min.css">

  <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">

  <link rel="stylesheet" href="/css/franklin.css">
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700"
    type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.min.css">
  <link rel="stylesheet" href="/css/celeste.min.css">

  <link rel="icon" type="image/png" sizes="200x200" href="/assets/robot.png">
  <!-- <link rel="shortcut icon" href="/assets/favicon.ico"> -->
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/assets/apple-touch-icon.png">


  <title>NLPwShiyi - Natural Language Processing with Shiyi</title>
</head>

<body>
  <!-- Latest compiled and minified CSS -->

  <nav id="navbar" class="navigation" role="navigation">
    <input id="toggle1" type="checkbox" />
    <label class="hamburger1" for="toggle1">
      <div class="top"></div>
      <div class="meat"></div>
      <div class="bottom"></div>
    </label>

    <nav class="topnav mx-auto" id="myTopnav">
      <div class="dropdown">
        <button class="dropbtn">Comp Ling
          <i class="fa fa-caret-down"></i>
        </button>
        <div class="dropdown-content">
          <a href="/modules/1a-info-theory">Information Theory</a>
          <a href="/modules/1b-phil-of-mind">Philosophy of Mind</a>
          <a href="/modules/1c-noisy-channel-model">The Noisy Channel Model</a>
          <a href="/modules/1d-finite-automata">FSAs and FSTs</a>
          <a href="/modules/1e-mutual-info">Mutual Information</a>
          <a href="/modules/1f-cky-algorithm">CKY Algorithm</a>
          <a href="/modules/1g-viterbi">Viterbi Algorithm</a>
          <a href="/modules/1h-semantics">Logic and Problem Solving</a>
          <a href="/modules/1i-cryptanalysis">Cryptography</a>
        </div>
      </div>
      <div class="dropdown">
        <button class="dropbtn">DL / NLP
          <i class="fa fa-caret-down"></i>
        </button>
        <div class="dropdown-content">
          <a href="/modules/2a-mdn-nlp">Modern NLP</a>
          <a href="/modules/2b-markov-processes">Markov Processes</a>
          <a href="/modules/2c-word2vec">Word2Vec</a>
          <a href="/modules/2d-automatic-differentiation">Automatic Differentiation</a>
          <a href="/modules/2e-jax">Jacobian Matrices Derivation</a>
          <a href="/modules/2f-loss-functions">Stochastic GD</a>
          <a href="/modules/2g-batchnorm">Batchnorm</a>
          <a href="/modules/2h-dropout">Dropout</a>
          <a href="/modules/2i-depth">Depth: Pros and Cons</a>
        </div>
      </div>
      <a href="/" class="active">Intro </a>
      <div class="dropdown">
        <button class="dropbtn">SOTA
          <i class="fa fa-caret-down"></i>
        </button>
        <div class="dropdown-content">
          <a href="/modules/3a-VAE">Variational Autoencoders</a>
          <a href="/modules/3b-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a>
          <a href="/modules/3c-transformers">Transformers</a>
          <!-- <a href="/modules/">TODO: Diffusion Prob Models</a> -->
        </div>
      </div>
      <div class="dropdown">
        <button class="dropbtn">Hands-on
          <i class="fa fa-caret-down"></i>
        </button>
        <div class="dropdown-content">
          <a href="/modules/4a-mlp-from-scratch">MLP from Scratch</a>
          <a href="/modules/4b-generative-adversarial-networks">GAN Example </a>
          <a href="/modules/4c-vae-mnist">VAE for MNIST</a>
          <a href="/modules/4d-bi-lstm-crf">BI-LSTM-CRF S2S</a>
          <a href="/modules/4e-c4fe-tbip">C4FE-TBIP</a>
          <a href="/modules/4f-etl-job">DE: Serverless ETL</a>

        </div>
      </div>
    </nav>
  </nav>

  <!-- Content appended here -->
  <div class="franklin-content">
    <h2 id="vae_for_mnist_image_classification"><a href="#vae_for_mnist_image_classification" class="header-anchor">VAE
        for MNIST Image Classification</a></h2>
    <div class="franklin-toc">
      <ol>
        <li><a href="#vae_for_mnist_image_classification">VAE for MNIST Image Classification</a></li>
        <li><a href="#breakdown_of_the_math">Breakdown of the Math</a></li>
        <li><a href="#cheating_with_the_conditional_vae">Cheating with the &#39;conditional&#39; VAE</a></li>
      </ol>
    </div>
    <p>In this section, we are going to go through some practical code examples of variational encoding method for MNIST
      image classification.</p>
    <pre><code class="language-python">import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms
from torchvision.utils import save_image

import numpy as np
import matplotlib.pyplot as plt
&#37;matplotlib inline

from sklearn.metrics.cluster import normalized_mutual_info_score

def show&#40;img&#41;:
    npimg &#61; img.numpy&#40;&#41;
    plt.imshow&#40;np.transpose&#40;npimg, &#40;1,2,0&#41;&#41;, interpolation&#61;&#39;nearest&#39;&#41;
    
def plot_reconstruction&#40;model, n&#61;24&#41;:
    x,_ &#61; next&#40;iter&#40;data_loader&#41;&#41;
    x &#61; x&#91;:n,:,:,:&#93;.to&#40;device&#41;
    try:
        out, _, _, log_p &#61; model&#40;x.view&#40;-1, image_size&#41;&#41; 
    except:
        out, _, _ &#61; model&#40;x.view&#40;-1, image_size&#41;&#41; 
    x_concat &#61; torch.cat&#40;&#91;x.view&#40;-1, 1, 28, 28&#41;, out.view&#40;-1, 1, 28, 28&#41;&#93;, dim&#61;3&#41;
    out_grid &#61; torchvision.utils.make_grid&#40;x_concat&#41;.cpu&#40;&#41;.data
    show&#40;out_grid&#41;

def plot_generation&#40;model, n&#61;24&#41;:
    with torch.no_grad&#40;&#41;:
        z &#61; torch.randn&#40;n, z_dim&#41;.to&#40;device&#41;
        out &#61; model.decode&#40;z&#41;.view&#40;-1, 1, 28, 28&#41;

    out_grid &#61; torchvision.utils.make_grid&#40;out&#41;.cpu&#40;&#41;
    show&#40;out_grid&#41;

def plot_conditional_generation&#40;model, n&#61;8, fix_number&#61;None&#41;:
    with torch.no_grad&#40;&#41;:
        matrix &#61; np.zeros&#40;&#40;n,n_classes&#41;&#41;
        matrix&#91;:,0&#93; &#61; 1

        if fix_number is None:
            final &#61; matrix&#91;:&#93;
            for i in range&#40;1,n_classes&#41;:
                final &#61; np.vstack&#40;&#40;final,np.roll&#40;matrix,i&#41;&#41;&#41;
            #z &#61; torch.randn&#40;8*n_classes, z_dim&#41;.to&#40;device&#41;
            z &#61; torch.randn&#40;8, z_dim&#41;
            z &#61; z.repeat&#40;n_classes,1&#41;.to&#40;device&#41;
            y_onehot &#61; torch.tensor&#40;final&#41;.type&#40;torch.FloatTensor&#41;.to&#40;device&#41;
            out &#61; model.decode&#40;z,y_onehot&#41;.view&#40;-1, 1, 28, 28&#41;
        else:
            z &#61; torch.randn&#40;n, z_dim&#41;.to&#40;device&#41;
            y_onehot &#61; torch.tensor&#40;np.roll&#40;matrix, fix_number&#41;&#41;.type&#40;torch.FloatTensor&#41;.to&#40;device&#41;
            out &#61; model.decode&#40;z,y_onehot&#41;.view&#40;-1, 1, 28, 28&#41;

    out_grid &#61; torchvision.utils.make_grid&#40;out&#41;.cpu&#40;&#41;
    show&#40;out_grid&#41;</code></pre>
    <pre><code class="language-python"># Device configuration
device &#61; torch.device&#40;&#39;cuda&#39; if torch.cuda.is_available&#40;&#41; else &#39;cpu&#39;&#41;

# Create a directory if not exists
sample_dir &#61; &#39;samples&#39;
if not os.path.exists&#40;sample_dir&#41;:
    os.makedirs&#40;sample_dir&#41;</code></pre>
    <pre><code class="language-python">data_dir &#61; &#39;data&#39;
# MNIST dataset
dataset &#61; torchvision.datasets.MNIST&#40;root&#61;data_dir,
                                     train&#61;True,
                                     transform&#61;transforms.ToTensor&#40;&#41;,
                                     download&#61;True&#41;

# Data loader
data_loader &#61; torch.utils.data.DataLoader&#40;dataset&#61;dataset,
                                          batch_size&#61;128, 
                                          shuffle&#61;True&#41;

test_loader &#61; torch.utils.data.DataLoader&#40;
    torchvision.datasets.MNIST&#40;data_dir, train&#61;False, download&#61;True, transform&#61;transforms.ToTensor&#40;&#41;&#41;,
    batch_size&#61;10, shuffle&#61;False&#41;</code></pre>
    <h2 id="breakdown_of_the_math"><a href="#breakdown_of_the_math" class="header-anchor">Breakdown of the Math</a></h2>
    <p>Consider a latent variable model with a data variable \(x\in \mathcal{X}\) and a latent variable \(z\in
      \mathcal{Z}\), \(p(z,x) = p(z)p_\theta(x|z)\). Given the data \(x_1,\dots, x_n\), we want to train the model by
      maximizing the marginal log-likelihood:</p>
    <div class="nonumber">\[\begin{array}{rcl}
      \mathcal{L} = \mathbf{E}_{p_d(x)}\left[\log p_\theta(x)\right]=\mathbf{E}_{p_d(x)}\left[\log
      \int_{\mathcal{Z}}p_{\theta}(x|z)p(z)dz\right]

      \end{array}\]</div>
    <p>where \(p_d\) denotes the empirical distribution of \(X\): \(p_d(x) =\frac{1}{n}\sum_{i=1}^n \delta_{x_i}(x)\).
    </p>
    <p>To avoid the &#40;often&#41; difficult computation of the integral above, the idea behind variational methods is
      to instead maximize a lower bound to the log-likelihood:</p>
    <div class="nonumber">\[\begin{array}{rcl}

      \mathcal{L} \geq L(p_\theta(x|z),q(z|x)) =\mathbf{E}_{p_d(x)}\left[\mathbf{E}_{q(z|x)}\left[\log
      p_\theta(x|z)\right]-\mathrm{KL}\left( q(z|x)||p(z)\right)\right]

      \end{array}\]</div>
    <p>Any choice of \(q(z|x)\) gives a valid lower bound. Variational autoencoders replace the variational posterior
      \(q(z|x)\) by an inference network \(q_{\phi}(z|x)\) that is trained together with \(p_{\theta}(x|z)\) to jointly
      maximize \(L(p_\theta,q_\phi)\)</p>
    <p>The variational posterior \(q_{\phi}(z|x)\) is also called the <strong>encoder</strong> and the generative model
      \(p_{\theta}(x|z)\), the <strong>decoder</strong> or generator.</p>
    <p>The first term \(\mathbf{E}_{q(z|x)}\left[\log p_\theta(x|z)\right]\) is the negative reconstruction error.
      Indeed under a gaussian assumption i.e. \(p_{\theta}(x|z) = \mathcal{N}(\mu_{\theta}(z), I)\) the term \(\log
      p_\theta(x|z)\) reduces to \(\propto \|x-\mu_\theta(z)\|^2\), which is often used in practice. The term
      \(\mathrm{KL}\left( q(z|x)||p(z)\right)\) can be seen as a regularization term, where the variational posterior
      \(q_\phi(z|x)\) should be matched to the prior \(p(z)= \mathcal{N}(0, I)\).</p>
    <p>Variational Autoencoders were introduced by <a href="https://arxiv.org/abs/1312.6114">Kingma and Welling
        &#40;2013&#41;</a>, see also <a href="https://arxiv.org/abs/1606.05908">&#40;Doersch, 2016&#41;</a> for a
      tutorial.</p>
    <p>There are various examples of VAE in PyTorch available <a
        href="https://github.com/pytorch/examples/tree/master/vae">here</a> or <a
        href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65">here</a>.
      The code below is taken from this last source.</p>
    <hr />
    <p><img src="../extras/dnns/vae.png" alt="vae" /></p>
    <hr />
    <pre><code class="language-python"># Hyper-parameters
image_size &#61; 784
h_dim &#61; 400
z_dim &#61; 20
num_epochs &#61; 15
learning_rate &#61; 1e-3

# VAE model
class VAE&#40;nn.Module&#41;:
    def __init__&#40;self, image_size&#61;784, h_dim&#61;400, z_dim&#61;20&#41;:
        super&#40;VAE, self&#41;.__init__&#40;&#41;
        self.fc1 &#61; nn.Linear&#40;image_size, h_dim&#41;
        self.fc2 &#61; nn.Linear&#40;h_dim, z_dim&#41;
        self.fc3 &#61; nn.Linear&#40;h_dim, z_dim&#41;
        self.fc4 &#61; nn.Linear&#40;z_dim, h_dim&#41;
        self.fc5 &#61; nn.Linear&#40;h_dim, image_size&#41;
        
    def encode&#40;self, x&#41;:
        h &#61; F.relu&#40;self.fc1&#40;x&#41;&#41;
        return self.fc2&#40;h&#41;, self.fc3&#40;h&#41;
    
    def reparameterize&#40;self, mu, log_var&#41;:
        std &#61; torch.exp&#40;log_var/2&#41;
        eps &#61; torch.randn_like&#40;std&#41;
        return mu &#43; eps * std

    def decode&#40;self, z&#41;:
        h &#61; F.relu&#40;self.fc4&#40;z&#41;&#41;
        return torch.sigmoid&#40;self.fc5&#40;h&#41;&#41;
    
    def forward&#40;self, x&#41;:
        mu, log_var &#61; self.encode&#40;x&#41;
        z &#61; self.reparameterize&#40;mu, log_var&#41;
        x_reconst &#61; self.decode&#40;z&#41;
        return x_reconst, mu, log_var

model &#61; VAE&#40;&#41;.to&#40;device&#41;
optimizer &#61; torch.optim.Adam&#40;model.parameters&#40;&#41;, lr&#61;learning_rate&#41;</code></pre>
    <p>Here for the loss, instead of MSE for the reconstruction loss, we take Binary Cross-Entropy. The code below is
      still from the PyTorch tutorial &#40;with minor modifications to avoid warnings&#33;&#41;.</p>
    <pre><code class="language-python"># Start training
for epoch in range&#40;num_epochs&#41;:
    for i, &#40;x, _&#41; in enumerate&#40;data_loader&#41;:
        # Forward pass
        x &#61; x.to&#40;device&#41;.view&#40;-1, image_size&#41;
        x_reconst, mu, log_var &#61; model&#40;x&#41;
        
        # Compute reconstruction loss and kl divergence
        # For KL divergence between Gaussians, see Appendix B in VAE paper or &#40;Doersch, 2016&#41;:
        # https://arxiv.org/abs/1606.05908
        reconst_loss &#61; F.binary_cross_entropy&#40;x_reconst, x, reduction&#61;&#39;sum&#39;&#41;
        kl_div &#61; - 0.5 * torch.sum&#40;1 &#43; log_var - mu.pow&#40;2&#41; - log_var.exp&#40;&#41;&#41;
        
        # Backprop and optimize
        loss &#61; reconst_loss &#43; kl_div
        optimizer.zero_grad&#40;&#41;
        loss.backward&#40;&#41;
        optimizer.step&#40;&#41;
        
        if &#40;i&#43;1&#41; &#37; 10 &#61;&#61; 0:
            print &#40;&quot;Epoch&#91;&#123;&#125;/&#123;&#125;&#93;, Step &#91;&#123;&#125;/&#123;&#125;&#93;, Reconst Loss: &#123;:.4f&#125;, KL Div: &#123;:.4f&#125;&quot; 
                   .format&#40;epoch&#43;1, num_epochs, i&#43;1, len&#40;data_loader&#41;, reconst_loss.item&#40;&#41;/len&#40;x&#41;, kl_div.item&#40;&#41;/len&#40;x&#41;&#41;&#41;</code></pre>
    <p>Let see how our network reconstructs our last batch. We display pairs of original digits and reconstructed
      version.</p>
    <pre><code class="language-python">plot_reconstruction&#40;model&#41;</code></pre>
    <p>Let&#39;s see now how our network generates new samples.</p>
    <pre><code class="language-python">plot_generation&#40;model&#41;</code></pre>
    <p>Not great, but we did not train our network for long... That being said, we have no control of the generated
      digits. In the rest of this notebook, we explore ways to generates zeroes, ones, twos and so on.</p>
    <p>As a by-product, we show how our VAE will allow us to do clustering thanks to the Gumbel VAE described below. But
      before that, we start by cheating a little bit...</p>
    <h2 id="cheating_with_the_conditional_vae"><a href="#cheating_with_the_conditional_vae"
        class="header-anchor">Cheating with the &#39;conditional&#39; VAE</a></h2>
    <p>We will first use the labels here &#40;like what we did in the course with Conditional GAN&#41;. The idea is to
      modify slightly the architecture above by feeding a one hot version of the label to the decoder in addition to the
      code computed by the decoder.</p>
    <p>First code a function transforming a label in its one hot encoding. This function will be used in the training
      loop &#40;not in the architecture of the neural network&#33;&#41;.</p>
    <pre><code class="language-python">n_classes &#61; 10
def l_2_onehot&#40;labels,nb_digits&#61;n_classes&#41;:
    # take labels &#40;from the dataloader&#41; and return labels onehot-encoded
    #
    # your code here
    #</code></pre>
    <p>You can test it on a batch.</p>
    <pre><code class="language-python">&#40;x,labels&#41; &#61; next&#40;iter&#40;data_loader&#41;&#41;</code></pre>
    <p>Now modify the architecture of the VAE where the decoder takes as input the random code concatenated with the
      onehot encoding of the label.</p>
    <pre><code class="language-python">n_classes &#61; 10

class VAE_Cond&#40;nn.Module&#41;:
    def __init__&#40;self, image_size&#61;784, h_dim&#61;400, z_dim&#61;20, n_classes &#61; 10&#41;:
        super&#40;VAE_Cond, self&#41;.__init__&#40;&#41;
        self.fc1 &#61; nn.Linear&#40;image_size, h_dim&#41;
        self.fc2 &#61; nn.Linear&#40;h_dim, z_dim&#41;
        self.fc3 &#61; nn.Linear&#40;h_dim, z_dim&#41;
        #
        # your code here
        #
        
    def encode&#40;self, x&#41;:
        h &#61; F.relu&#40;self.fc1&#40;x&#41;&#41;
        return self.fc2&#40;h&#41;, self.fc3&#40;h&#41;
    
    def reparameterize&#40;self, mu, log_var&#41;:
        std &#61; torch.exp&#40;log_var/2&#41;
        eps &#61; torch.randn_like&#40;std&#41;
        return mu &#43; eps * std

    def decode&#40;self, z, l_onehot&#41;:
        #
        # your code here / use torch.cat 
        #      
    
    def forward&#40;self, x, l_onehot&#41;:
        #
        # your code here / use F.gumbel_softmax
        #</code></pre>
    <p>Test your new model on a batch:</p>
    <pre><code class="language-python">model_C &#61; VAE_Cond&#40;&#41;.to&#40;device&#41;
x &#61; x.to&#40;device&#41;.view&#40;-1, image_size&#41;
l_onehot &#61; l_2_onehot&#40;labels&#41;
l_onehot &#61; l_onehot.to&#40;device&#41;
model_C&#40;x, l_onehot&#41;</code></pre>
    <p>Now you can modify the training loop of your network. The parameter will allow you to scale the KL term in your
      loss as explained in the \(\beta\) -VAE paper see formula &#40;4&#41; in the paper.</p>
    <pre><code class="language-python">def train_C&#40;model, data_loader&#61;data_loader,num_epochs&#61;num_epochs, beta&#61;10., verbose&#61;True&#41;:
    nmi_scores &#61; &#91;&#93;
    model.train&#40;True&#41;
    for epoch in range&#40;num_epochs&#41;:
        for i, &#40;x, labels&#41; in enumerate&#40;data_loader&#41;:
            # Forward pass
            x &#61; x.to&#40;device&#41;.view&#40;-1, image_size&#41;
            #
            # your code here
            #
            
            
            reconst_loss &#61; F.binary_cross_entropy&#40;x_reconst, x, reduction&#61;&#39;sum&#39;&#41;
            kl_div &#61;  - 0.5 * torch.sum&#40;1 &#43; log_var - mu.pow&#40;2&#41; - log_var.exp&#40;&#41;&#41;
            
            # Backprop and optimize
            loss &#61; reconst_loss &#43; beta*kl_div
            optimizer.zero_grad&#40;&#41;
            loss.backward&#40;&#41;
            optimizer.step&#40;&#41;
            
            if verbose:
                if &#40;i&#43;1&#41; &#37; 10 &#61;&#61; 0:
                    print&#40;&quot;Epoch&#91;&#123;&#125;/&#123;&#125;&#93;, Step &#91;&#123;&#125;/&#123;&#125;&#93;, Reconst Loss: &#123;:.4f&#125;, KL Div: &#123;:.4f&#125;&quot;
                           .format&#40;epoch&#43;1, num_epochs, i&#43;1, len&#40;data_loader&#41;, reconst_loss.item&#40;&#41;/len&#40;x&#41;,
                                   kl_div.item&#40;&#41;/len&#40;x&#41;&#41;&#41;</code></pre>
    <pre><code class="language-python">model_C &#61; VAE_Cond&#40;&#41;.to&#40;device&#41;
optimizer &#61; torch.optim.Adam&#40;model_C.parameters&#40;&#41;, lr&#61;learning_rate&#41;</code></pre>
    <pre><code class="language-python">train_C&#40;model_C,num_epochs&#61;15,verbose&#61;True&#41;

plot_conditional_generation&#40;model_C, n&#61;8&#41;</code></pre>
    <p>Here you should get nice results. Now we will avoid the use of the labels...</p>
    <div class="page-foot">
      <div class="copyright">
        <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class="github-logo"
              src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></img></b></a></br>
        ©️ Last modified: March 12, 2024. Website built with <a
          href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia
          programming language</a>.
      </div>
    </div>
  </div><!-- CONTENT ENDS HERE -->

  <script src="/libs/katex/katex.min.js"></script>
  <script src="/libs/katex/contrib/auto-render.min.js"></script>
  <script>
    renderMathInElement(document.body)

  </script>



  <script src="/libs/highlight/highlight.min.js"></script>
  <script>
    hljs.highlightAll();
    hljs.configure({
      tabReplace: '    '
    });

  </script>


</body>

</html>
