# What Constitutes As The Philosophy of Mind？

This blog will summarize articles, papers, and material I have gone through that touch on the subject of _The Computational Theory of Mind_.

In this one article that touches on this subject, it's known that the computational theory of mind promises us the abilities of a machine to emulate reasoning, decision-making, problem solving, perception, linguistic comprehension, and other mental processes.

**Table Of Contents**

---

\toc

---

Advances in computing raise the prospect known as _The Computational Theory of Mind_ (CTM). Computationalists understand this paradigm as the principle to cognitive science. Then later two schools of thoughts challenged this orthodox position.

One pertains to the neurological properties of the mind and body and the other emphasized representational mental states.

### Computationalism vs The Classical Computational Theory of Mind

On the other hand, according to CCTM, the mind is a computational system similar in important respects to a Turing machine, and core mental processes (e.g., reasoning, decision-making, and problem solving) are computations similar in important respects to computations executed by a Turing machine.

First, CCTM is better formulated by describing the mind as a “computing system” or a “computational system” rather than a “computer”. As David Chalmers - an Australian philosopher and cognitive scientist specializing in the areas of philosophy of mind and philosophy of language - (2011) notes, describing a system as a “computer” strongly suggests that the system is programmable. As Chalmers also notes, one need not claim that the mind is programmable simply because one regards it as a Turing-style computational system.

Second, CCTM is not intended metaphorically. CCTM does not simply hold that the mind is like a computing system. CCTM holds that the mind `literally is a computing system`. The most familiar artificial computing systems are made from silicon chips or similar materials, whereas the human body is made from flesh and blood. But CCTM holds that this difference disguises a more fundamental similarity, which we can capture through a Turing-style computational model.

In offering such a model, we prescind from physical details. We attain an abstract computational description that could be physically implemented in diverse ways (e.g., through silicon chips, or neurons, or pulleys and levers). CCTM holds that a `suitable abstract computational model offers a literally true description of core mental processes`.

The turing machine - or the earliest computational model is a device that assumes unlimited time and storage at its disposal. The device manipulates symbols, much as a human doing type-writing and creating characters on a paper.  In actuality, this would not be possible. A few important components and limitations,

---

@@colbox-blue

#### A Turing Style Computational System 

1. memory locations: assuming an infinitely long linear structure or system, here is where these symbols might be kept. There are always ways to optimize memory locations and storage space, including through the use of techniques like hashing (because the implementation could not realistically assume infinity).
2. a central processor, which has a limited number of machine states it can enter.
3. The central processor's basic actions on symbols include writing and deleting symbols as well as accessing the next memory position in the linear array. (On the tape, veer to the left or right).
4. two key principles are used in the operation to process the data: the current symbol that is stored at the current memory address, and the scanner's own current machine state.
5. a machine table, which, based on the central processor's present machine state and the symbol it is currently accessing, determines which elementary operation it will carry out.
   It also determines how those same circumstances affect the machine state of the central processor.
6. human cognitive constraints - lastly, the symbolic system that the Turing computer symbolizes could effectively duplicate it due to our cognitive constraints, which can only yield a certain number of possibilities.
   @@

---

One important breakthrough invention during the computationalism era was the _Logic Theorist_ computer program (Newell and Simon 1956) which proved 38 of the first 52 theorems from _Principia Mathematica_ (Whitehead and Russell 1925).

Since the discrete nature of the system, it's concerned with its competency of whether it could model the continuous nature of human cognition. There's between the _digital_ paradigm behind the system with _analog_ system.

The Turing machine also proved the existence of a _Universal Turing Machine_ (UTM), which results in the ultimate development of current computer logic and system. More importantly, a personal computer can mimic any Turing machine _until it exhausts its limited memory supply_.

### The Representational vs The Classical Computational Theory of Mind

As opposed to type-identity theory, mental states are brain states. Putnam proposed a different view that mental states are [_multiply realizable_](https://plato.stanford.edu/entries/multiple-realizability/): the same mental state can be realized by diverse physical systems, including not only terrestrial creatures but also hypothetical creatures.

```
Functionalism therefore is tailor-made to accommodate multiple realizability.
```

He stresses the importance of _probabilistic automata_, stating that mental states are the machine states of the automaton's central processor. However, the weakness of this thought lies in the fact that human cognition has limitations and couldn't entertain infinite amount of propositions and possibilities.

Another important limitation with this is that _probabilistic automata_ doesn't reflect the systematicity inside these mental states.

```plaintext
Productivity: 
  
RTM assumes a finites set of symbols in natural language and the device could entertain a infinite numbers of logic.

Systematicity:

RTM also assumes that there are inherent systematic relations between basic cognitive constitutions.
```

Therefore, to reflect such a mental image, the CCTM+RTM must be representational or schematic. This entails that the system will provide an elementary operations with specific rules that's manifested in a plan.

For example, in constructing syntax trees, this will be reflected as having a lexicon (which represents the productivity that reflects the natural language which reflects the mental thought processes), part-of-speech tags (the elementary operations that could be used over the lexicon).

And the final drawing of a syntax tree (the rules that govern where those tags go so that they will be governed by routine instructions).

#### Computationalism vs Functionalism

There is a slight difference between computationalism and functionalism.

```
As per definition, the mind is the functional organization of the brain, whereas 
computationalism argues that the functional organization of the brain is computable so namely 
the mind is computable.
```

Hilary Putnam (1967) introduced CCTM into philosophy. His position with _logical behaviorism_ and _type-identity theory_.

---

@@colbox-blue

#### Logical Behaviorism vs Type/Token-Identity Theory

Logical behaviorism holds that all thoughts, perceptions, and other mental processes can be classified in the same way that mathematics can be explained in terms of formal logic, using concepts like set theory, and can then be **tested and scientifically explained using behaviorist principles**, according to which everything is made up of **stimulus-response** pairs with various types of origins and reinforcement.

According to type/topken-identity theory, the experience of something is considered to be a brain process that is occurring not merely as a mental state. Identity theorists additionally contend that brain states are just **physical**, which contradicts the irreducible non-physical aspects known as "qualia" of the brain, such as desires and beliefs.

In short,

* Logical behaviorism focuses on the relationship between mental states and observable behavior.
* Type/token identity theory focuses on the relationship between mental states and physical states of the brain.

@@

---

In the paper "The 'Mental' and the 'Physical'", where the re-known philosopher J.J.C. Smart (crediting the term to Herbert Feigl) presented his theories about 'is consciousness a brain process?"

He argues a position coined as the "Nomological dangler" about "Sensations and Brain Processes", which refers to the occurrences of something that does not fit into the system of established laws.

He argues against the dualists' and [epiphenomenalism](https://en.wikipedia.org/wiki/Epiphenomenalism)'s position on the dichotomy between mind-body, stating that according to Occam's razor seeing a mental process like consciousness as purely physical gets rid of the hassle of not having been able to explain the grey area of what these brain processes actually are in a more scientific and established system.

To quote him more specifically,

```plaintext
It was believed that it is absurd that everything can be explained by the laws of physics except consciousness. 
In this case, he identifies consciousness with the broad term "sensations".
```

### Conscious Automata and the Definition of Consciousness

The debate about what human beings are really have been going on for centuries. According to the prominent English biologist Thomas Henry Huxley (1825-1895), he believed that sensations and feelings are mere byproduct of mechanics of the brain. An epiphenomenon that is not the cause of any behavior. In his essay, "On the Hypothesis that Animals Are Automata, and Its History" he wrote:

---

@@colbox-blue

#### What Does It Mean By Consciousness?

The consciousness of brutes would appear to be related to the mechanism of their body simply as a collateral product of its working, and
to be as completely without any power of modifying that working as the steam-whistle which accompanies the work of a locomotive engine is
without influence upon its machinery.

_Their volition, if they have any, is an emotion indicative of physical changes, not a cause of such
changes. […]_

It is quite true that, to the best of my judgment, the argumentation which applies to brutes holds equally good of men;
and, therefore, that all states of consciousness in us, as in them, are immediately caused by molecular changes of the brain-substance.
It seems to me that in men, as in brutes, there is no proof that any state of consciousness is the cause of change in the motion of
the matter of the organism.
@@

---

The primal instincts vs. the unknown. The necessity  of consciousness has been a hotly debated topic. A few primal physical responses of humans have indicated that humans could task being an automata without these familiar yet mysterious qualia. For example, humans could drive while talk, have fight-and-flight responses without being aware of it, and blindsight which are sensational responses to visual stimuli without actually experiencing the effects visually.

Lastly, onto the discussions about pain. It seems that the presence of pain is superfluous. We need not to have to experience pain to understand to the risk of injury and be avoidance of danger.

ℹ️ So why isn't this indication enough for such a phenomenon enough to explain what these "nomologically dangling" ideas? And what exactly is the purpose of and function of consciousness?

One answer to the questions argues that they are not merely physical,it's the nature's decision bestowed upon us with free will. It lets us to decide with this warning sign. It's more so a trade-off handed over to our free will. We experience discomfort caused by external stimulation and then we are given the option to consciously decide what we are going to do with it.

Another objection to the byproduct hypothesis would be that,

---

@@colbox-blue

#### The Functionality and Usability of Affective Values

If pleasure and discomfort have no consequences, there would seem to be no reason why we couldn't detest the feelings brought on by necessary actions or relish them when generated by harmful ones.

Therefore, if epiphenomenalism were accurate, it would be necessary to provide a special justification for the harmonious relationship between our feelings' affective value and their usefulness in our daily lives. Nevertheless, this alignment could not have a true explanation based on epiphenomenalist presumptions.

Affective valuation would not have any behavioral implications if it were misaligned with the usefulness of the causes of the evaluated sensations, and vice versa. Therefore, the felicitous alignment could not be chosen.

Epiphenomenalists would only be left with the option of accepting a crude and unscientific understanding of the pre-existing harmony of affective appraisal of feelings and the usefulness of their sources.

@@

---

#### Consciousness As Strong Emergence

This is the position that is too good to be true and argued against. As it's not very much plausible that it's the downward causal direction, where the emergence of consciousness caused the microscopic and molecular changes happening at a lower-level. The only justification to this position is that it opens up possibilities for free will. As explained by the physicist Sean Carroll,

---

@@colbox-blue

#### Strong vs Weak Emergence

So-called “weak” emergence just says the obvious thing, that higher-level notions like the fluidity or solidity of a material substance emerge out of the properties of its microscopic constituents. In principle, if not in practice, the microscopic description is absolutely complete and comprehensive. A “strong” form of emergence would suggest that something truly new comes into being at the higher levels, something that just isn’t there in the microscopic description.

Downward causation is one manifestation of this strong-emergence attitude. It’s the idea that what happens at lower levels can be directly influenced (causally acted upon) by what is happening at the higher levels. The idea, in other words, that you can’t really understand the microscopic behavior without knowing something about the macroscopic.

@@

---

#### Consciousness As The Fundamental Property of Nature

In answering the question of why we need consciousness, the proposed answer is that consciousness is a fundamental property of nature. It's added that

```plaintext
“We know that a theory of consciousness requires the addition of something fundamental to our ontology, as everything in physical theory is compatible with the absence of consciousness.
We might add some entirely new nonphysical feature, from which experience can be derived […] we will take experience itself as a fundamental feature of the world, alongside mass, charge, and space-time”.
```

This is also known as "fundamental property dualism", which, in David Chalmers' definition, _"regards conscious mental properties as basic constituents of reality on a par with fundamental physical properties such as electromagnetic charge. They may interact in casual and lay-like ways with other fundamental properties such a those of physics, but ontologically  their existence is not dependent upon nor derivative from any other properties"._

According to this [medium article](https://medium.com/curious/are-we-conscious-automata-18ba889af20), this idea is also referred to as panpsychism, which “holds that mind or a mind-like aspect is a fundamental and ubiquitous feature of reality. It is also described as a theory that “the mind is a fundamental feature of the world which exists throughout the universe.”

#### Consciousness As Normal Emergence

Instead of being a strong emergence, maybe in reality consciousness might just be a weak emergence instead as proposed. It's proposed in the article, it's important to use language in context when talk about different subjects in question.

The example used was when we talk about atoms and other physical properties, it might not be suitable to talk about free will, but under the philosophical discussions about human consciousness, motivation, and behavior, it may be otherwise.

ℹ️ In such a case, explaining what a weak emergence is, we may ask the question: if we take the view that consciousness does affect our thoughts and behavior, is that view applicable at the level of atoms and particles, or only at the level appropriate for describing human psychology?

```plaintext
In answering this question, the article used a different analogy; consider the mechanism that regulates the constriction and dilation of our pupils according to the intensity of the light reaching them. We could say that there's a sort of sensor in our eyes or in our visual processing area in the brain that causes our pupils to behave that way, yet at the fundamental level of physics, the knowledge of such a sensory mechanism is not needed to predict (in principle) the behavior of all the particles composing the eye as they interact among themselves and with all the external particles affecting them. Still, we wouldn't say that the sensor is merely a byproduct that accomplishes nothing.
```

The visual sensor is obviously affecting the behavior of the pupil, yet it doesn't follow that it's affecting the behavior of the underlying atoms in a way that contradicts or is incompatible with our understanding of how atoms behave.

Without the sensor, the atoms wouldn't behave as they do, and in that sense the sensor is necessary for the pupil to constrict and dilate; it's that it's necessary to know the existence of the sensor to predict what the atoms of the eye will do next.

In the domain that deals with how the eye works, it's useful and practical to speak of some  sort of sensory mechanism; in the domain that deals with how atoms behave, it isn't - it isn't even necessary. Perhaps we could understand consciousness in the same way.

### Tying Everything Together and Connecting The Dots

Coming back to computers and their connections with human brain and consciousness. Philosophers started to become interested in connectionism because it offers an alternative to the classical computational theory of mind.

```plaintext
Connectionism is a movement that has been put out in the field of cognitive science in hope to explain and extrapolate the mental processes of a brain. It's composed of a simplified emulation of the actual cognitive compositions of a brain, by having connected neurons or units (the analogs of neurons) within which are assigned weights that measure how strongly the connections are there between units. We could picture these weights as a replica of the synapse in our actual biological brain that link one neuron to each other.
```

The bridging between classicist and connectionist view and the departure from it became that a lot of connectionist view cognitive processing as analog as the computer processing as digital.

Many connectionists argue that weight units that are dynamic, continuous, and analogous in nature which therefore reflect better the way that human brain processes information through different mental states.

On the other hand, classicists view information processing done by humans as similar to a computational system where information is stored symbolically and processed systematically through automatons.
And the storing of information is similar to that of a computer where there's "memory locations" for information access and retrieval.

However, many connectionists seek to bridge these two paradigms together instead of trying to argue for one over the other. One of the schools - the implementational connectionists - seeks to find a solution that accommodates these two different hypotheses.

However, it's also argued by radical connectionists that the traditional or the symbolic way of treating human cognitive information processing should be eliminated because how poorly it reflects these dynamics in human consciousness that could otherwise be materialized through connectionism,

```plaintext
graceful degradation of function, holistic representation of data, spontaneous generalization, appreciation of context, etc.
```

Yet, hybrid mechanisms were put out by different teams to mediate such clashes. For example, there were papers that drew inspiration from the classical style of information processing (having one module that acts as the memory location or implementing methods that utilize variable binding techniques for symbolic processing that reflects the classical computational way of thinking aka the turing style information processing and storage).

This hybrid architecture might have had a say to how human brains actually process information, which is that symbolic processing might actually be present in the brain.

```plaintext
Also one interesting discovery about the connectionism representation of information processing inside the brain might have a good give away of how brain actually processes information.

That is, instead of a local representation of an individual or specific informational unit, the learning mechanism is more so universally distributed across different (hidden) units.

To top it off, the new way of representing information's sub-symbolic nature - where there were no intrinsic properties of representations that determine their relationships with other symbols - might solve a philosophical conundrum in representations of meaning.

In contrast, a distributed representation preserves patterns across the net that could allow comparison and good preservation when parts go amok.
```

However, the classicists argue that connectionists approach lack proper explanation to the important intrinsic property of human cognition - **systematicity** and **productivity**. This brings the conversation back to language processing; different from other types of artificial intelligence tasks such as image and audio processing, because of the associative nature of connectionism, with distributed representations, these tasks could be managed and tackled relatively with ease, language processing needs a more complex system to account for its intrinsic nature of systematicity.

This is the hot debate between these two different schools of thoughts with the conclusion that connectionism might not be able to account for higher human cognition; the success could only come about if the two paradigms combine.

**References**

_Rescorla, Michael, "The Computational Theory of Mind", The Stanford Encyclopedia of Philosophy (Fall 2020 Edition), Edward N. Zalta (ed.)_

<!-- ### Topics That Might Be Relevant To This Blog

- Topic 2a: Computationalism

  - [Subtpoic 0: Chomsky Hierarchy](./modules/chomsky-hierarchy)
  - [Subtopic 1: Context Free Grammar](./modules/context-free-grammar)
  - [Subtopic 2: Finite State Automata and Transducers](./modules/finite-stat-automata)
  - [Subtopic 3: Linguistic Trees](./modules/linguistic-trees)
  - [Subtopic 4: Parsing](./modules/parsing)
  - [Subtopic 5: Hidden Markov Model](./modules/hidden-markov-model)
  - [Subtopic 6: Word Net](./modules/word-net)
  - [Subtopic 7: Heuristics](./modules/universal-dependencies)
  - [Subtopic 8: Continuous BOW And Skip-gram](./modules/universal-dependencies)
  - [Subtopic 9: Mutual Information](./modules/universal-dependencies)
  - [Subtopic 10: Viterbi Dynamic Programming](./modules/universal-dependencies)
  - [Subtopic 11: Formal Logic Systems, General Problem Solving, and Philosophy of Language](./modules/universal-dependencies)
  - [Subtopic 12: Syntactic Theory, Taxonomy, and Orthography](./modules/universal-dependencies)
- Topic 2b: Connectionism

  - [Subtopic 2a: Pytorch Tensors](./modules/2a-pytorch-tensors)
  - [Subtopic 2b: Automatic Differentiation](./modules/2b-automatic-differentiation)
  - [Subtopic 3: Loss functions for classification](./modules/3-loss-functions-for-classification)
  - [Subtopic 4: Optimization for Deep Learning](./modules/4-optimization-for-deep-learning)
  - [Subtopic 5: Stacking layers](./modules/5-stacking-layers)
  - [Subtopic 6: Convolutional Neural Network](./modules/6-convolutional-neural-network)
  - [Subtopic 7a: Embedding layers and dataloaders](./modules/7a-embedding-layers-dataloaders)
  - [Subtopic 7b: Collaborative Filtering](./modules/7b-collaborative-filtering)
  - [Modules 8: Autoencoders and Transformers](./modules/8-autoencoders)
  - [Subtopic 9: Generative Adversarial Networks](./modules/9-generative-adversarial-networks)
  - [Subtopic 10: Recurrent Neural Networks](./modules/10a-recurrent-neural-networks) -->
