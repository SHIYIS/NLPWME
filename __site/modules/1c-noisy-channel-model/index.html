<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
  

  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css">
<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/celeste.min.css">

<link rel="icon" type="image/png" sizes="200x200" href="/assets/robot.png">
<!-- <link rel="shortcut icon" href="/assets/favicon.ico"> -->
<link rel="icon" type="image/png" sizes="152x152" href="/assets/robot_smaller_152x152.png">
<link rel="icon" type="image/x-icon" sizes="64x64" href="/assets/robot_smaller_64x64.png">
<link rel="icon" type="image/x-icon" sizes="32x32" href="/assets/robot_smaller_32x32.png">
<link rel="icon" type="image/png" sizes="64x64" href="/assets/robot_smaller_64x64.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/robot_smaller_32x32.png">


   <title>NLPwShiyi - Natural Language Processing with Shiyi</title>  
</head>
<body>
  <!-- Latest compiled and minified CSS -->

<nav id="navbar" class="navigation" role="navigation">
  <input id="toggle1" type="checkbox" />
  <label class="hamburger1" for="toggle1">
    <div class="top"></div>
    <div class="meat"></div>
    <div class="bottom"></div>
  </label>

  <nav class="topnav mx-auto" id="myTopnav">
    <div class="dropdown">
      <button class="dropbtn">Comp Ling
        <i class="fa fa-caret-down"></i>
      </button>
      <div class="dropdown-content">
        <!-- <a href="/modules/1a-phil-of-mind">Philosophy of Mind</a> -->
        <a href="/modules/1b-info-theory">Information Theory</a>
        <a href="/modules/1c-noisy-channel-model">The Noisy Channel Model</a>
        <a href="/modules/1d-finite-automata">FSAs and FSTs</a>
        <a href="/modules/1e-mutual-info">Mutual Information</a>
        <a href="/modules/1f-cky-algorithm">CKY Algorithm</a>
        <a href="/modules/1g-viterbi">Viterbi Algorithm</a>
        <a href="/modules/1h-semantics">Logic and Problem Solving</a>
        <!-- <a href="/modules/1i-cryptanalysis">Cryptography</a> -->
      </div>
    </div>
    <div class="dropdown">
      <button class="dropbtn" >DL / NLP
        <i class="fa fa-caret-down"></i>
      </button>
      <div class="dropdown-content">
        <!-- <a href="/modules/2a-mdn-nlp">Modern NLP</a> -->
        <a href="/modules/2b-markov-processes">Markov Processes</a>
        <a href="/modules/2e-jax">Jacobian Matrices Derivation</a>
        <a href="/modules/2d-automatic-differentiation">Automatic Differentiation</a>
        <a href="/modules/2f-loss-functions">Stochastic GD</a>
        <a href="/modules/2c-word2vec">Word2Vec</a>
        <a href="/modules/2g-batchnorm">Batchnorm</a>
        <a href="/modules/2j-perplexity">Perplexity</a>
        <a href="/modules/2h-dropout">Dropout</a>
        <a href="/modules/2i-depth">Depth: Pros and Cons</a>
        <a href="/modules/2k-VAE">Variational Autoencoders</a>
        <a href="/modules/2l-dnns">DNNs(RNNs, CNNs, (Bi)-LSTM)</a>
      </div>
    </div>
    <a href="/" class="active">Intro </a>
    <div class="dropdown">
      <button class="dropbtn" >SOTA
        <i class="fa fa-caret-down"></i>
      </button>
      <div class="dropdown-content">

        <a href="/modules/3a-transformers"> GPT (Generative Pre-trained Transformer) </a>
        <a href="/modules/3b-xlnet"> XLNet (Generalized Autoregressive Pretraining) </a>
        <a href="/modules/3c-roberta"> RoBERTa (Robustly optimized BERT approach) </a>
        <a href="/modules/3d-t5"> T5 (Text-to-Text Transfer Transformer) </a>
        <a href="/modules/3e-clip"> CLIP (Contrastive Language-Image Pre-training) </a>
        
        <!-- <a href="/modules/">TODO: Diffusion Prob Models</a> -->
      </div>
    </div>
    <div class="dropdown">
      <button class="dropbtn" >Hands-on
        <i class="fa fa-caret-down"></i>
      </button>
      <div class="dropdown-content">
        <a href="/modules/4a-mlp-from-scratch">MLP from Scratch</a>
        <a href="/modules/4b-generative-adversarial-networks">GAN Example </a>
        <a href="/modules/4c-vae-mnist">VAE for MNIST</a>
        <a href="/modules/4d-bi-lstm-crf">BI-LSTM-CRF Seq2Seq</a>
        <a href="/modules/4e-c4fe-tbip">Text-based Ideal Points Model</a>
        <!-- <a href="/modules/4f-server-build">WebServer Build Example</a> -->
        <a href="/modules/4g-etl-job">Serverless ETL Example</a>
        <a href="/modules/4h-ocr-data-aug">OCR Text Augmentation</a>
        <a href="/modules/4i-neo4j-gql">Neo4j GQL Example</a>
        <!-- <a href="/modules/4j-amr-parser">AMR Parser Example</a> -->


        

      </div>
    </div>
  </nav>
</nav>
  
  
<!-- Content appended here -->
  <!-- {{if hascode}} {{insert copy_paste.html}} {{end}} --><div class="franklin-content"><h1 id="how_everything_started"><a href="#how_everything_started" class="header-anchor">How Everything Started</a></h1>
<p>Table of Contents</p>
<div class="franklin-toc"><ol><li><a href="#what_exactly_is_a_noisy_channel_model">What Exactly Is A Noisy Channel Model?</a></li><li><a href="#one_of_the_most_important_masters_theses_in_the_20th_century">One of The Most Important Master&#39;s Theses In The 20th Century</a></li><li><a href="#the_morse_code">The Morse Code</a></li><li><a href="#another_important_equation">Another Important Equation</a></li><li><a href="#bayes_to_the_rescue">Bayes To The Rescue</a></li></ol></div>
<p>Hi there, if you have come across this blog and have the patience to go through it with me, by the end of it you will get to know and understand what noisy channel model that Claude E. Shannon first presented and experimented with back in the 40s really is. And you will also get to understand why it is important for our discussion. </p>
    <div id="videoContainer" >
            <div id="player"></div>        
    </div>
    <script>
    var tag = document.createElement('script');

    tag.src = "https://www.youtube.com/iframe_api";
    var firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

    var player;

    function onYouTubeIframeAPIReady() {
        player = new YT.Player('player', {
            width: '100%',
            position: 'relative',
            left: '0px',
            videoId: 'zjWXLD_ihOc',
            playerVars: {
                'autoplay': 0,
                'rel': 0,
                'cc_load_policy': 1
            }
        });
    }

    function changeYouTubeSource(startTime, endTime) {

        var youtubeIframe = document.getElementById('player');

        var youtubeIframeSrc = document.getElementById('player').getAttribute('src');

        var trimmedIframeUrl = '';
        var iframeUrlTimeStamp = '';

        if (youtubeIframeSrc.match(/&start=/g)) {
            var mediaFragmentIndex = youtubeIframeSrc.indexOf('&start=');
            trimmedIframeUrl = youtubeIframeSrc.slice(0, mediaFragmentIndex);

            if (endTime === 0) {
                iframeUrlTimeStamp = trimmedIframeUrl + '&start=' + startTime;
            } else {
                iframeUrlTimeStamp = trimmedIframeUrl + '&start=' + startTime + '&end=' + endTime;
            }
        }

        if (youtubeIframeSrc.match(/&start=/g) === null) {
            if (endTime === 0) {
                iframeUrlTimeStamp = youtubeIframeSrc + '&start=' + startTime;
            } else {
                iframeUrlTimeStamp = youtubeIframeSrc + '&start=' + startTime + '&end=' + endTime;
            }
        }

        setTimeout(function() {

            var iframeAutoplayUrl = iframeUrlTimeStamp.replace('autoplay=0', 'autoplay=1');

            youtubeIframe.setAttribute('src', iframeAutoplayUrl);
        }, 1000);
}
    </script>
    
<h3 id="what_exactly_is_a_noisy_channel_model"><a href="#what_exactly_is_a_noisy_channel_model" class="header-anchor">What Exactly Is A Noisy Channel Model?</a></h3>
<p>It&#39;s a system designed to capture how information gets transmitted.  It&#39;s also a mathematical or probabilistic model developed to capture the way signals get transmitted. </p>
<h3 id="one_of_the_most_important_masters_theses_in_the_20th_century"><a href="#one_of_the_most_important_masters_theses_in_the_20th_century" class="header-anchor">One of The Most Important Master&#39;s Theses In The 20th Century</a></h3>
<p>A Symbolic Analysis of Relay and Switching Circuits. Shannon&#39;s paper examines symbolic logic of 19th century English mathematician George Boole, and presents how the boolean logic could have a profound impact on electronic circuit design. Which is the entropy equation </p>
\[\text{H} = -\sum \text{p}_{i} \text{log}_{i}  \text{p}_{i}\]
<p>The equation we have discussed in another blog defines the information source in terms of the probability distribution of symbols being produced by that information source. </p>
<p>This equation marks the fundamental mechanism behind it, which has to do with the level of uncertainty in information. </p>
<h3 id="the_morse_code"><a href="#the_morse_code" class="header-anchor">The Morse Code</a></h3>
<p>The model is created by having a message written in English encoded in Morse code. The message then gets trasmitted over telegraph line. There&#39;s the noise coming from the transmission line. At the receiving end, another telegraph line receives the message and decodes the message. The decoded message then gets stored as human readable form. The final message may contain errors. </p>
<p>Let&#39;s break down the components of the noisy channel model,</p>
<ul>
<li><p>The model begins with an information source that&#39;s written in human language. </p>
</li>
<li><p>The message is encoded by the transmitter from English in to Morse code then sent from the channel to the telegraph line. </p>
</li>
<li><p>The message then gets sent to the receiver to the receiver for decoding. </p>
</li>
<li><p>Because of the noise in the channel, the final decoded message may contain errors.</p>
</li>
</ul>
<h3 id="another_important_equation"><a href="#another_important_equation" class="header-anchor">Another Important Equation</a></h3>
<p>Here I will follow the video and jot down the important equation that represents the transmission of a message through the noisy channel. </p>
<p>Below is the equation. So, here <code>e</code> and/or <code>f</code> represents respectively the message that gets encoded and sent in the channel and the output message that gets decoded back to human readable language. </p>
<p>Here as we are looking at the equation, given the output message <code>f</code>, we want to reconstruct the message back to <code>e</code>, by finding the <code>e</code> that maximizes the probability of <code>f</code> given <code>e</code>. Whatever <code>e</code> hat that satisfies our conditions will be the best hypothesis. </p>
\[\hat{e} = \underset{e}{\arg\max} \ p(\text{e|f})\]
<h3 id="bayes_to_the_rescue"><a href="#bayes_to_the_rescue" class="header-anchor">Bayes To The Rescue</a></h3>
<p>To calculate the probability, we are going to use an important mathematical law, the Bayes equation. </p>
\[p(\text{e|f}) = \frac{p(\textbf{f|e})p(\textbf{e})}{\textbf{f}} \]
<p>We will be talking about this God of an equation independently in another blog, but here we could understand that we are able to calculate the above noisy channel model through using the Bayes&#39; law. And the three components available in the equation will allow us to do this. </p>
<p>The posterior function which is intuitively the outcome function \(p(\text{e|f})\) is derived from the likelihood function which is the probability of <code>e</code> given <code>f</code> or \(p(\text{f|e})\) and the prior distributions \(p(e)\) together divided by the prior distribution of \(p(f)\).</p>
<p>Given this definition, we could redefine our previous definition in terms of the channel model and the language models.</p>
<p>First we do it by taking the posterior solution \(p(\text{e|f})\) and replace it with the right-hand side of the Bayes&#39; Law. According to the tutorial video, we could simplify the equation a little bit. </p>
<p>Recall performing an arg max operation over English messages <code>e</code>, this means we are looking for the English message <code>e</code>, which maximizes the total value of the equation. </p>
<p>Since <code>e</code> doesn&#39;t show up in the denominator, so no matter what value <code>e</code> has, won&#39;t be affected which leaves us with the final equation,</p>
\[\hat{e} = \underset{e}{\arg\max} (\text{f|e}) \ p(\text{e})\]
<div class="page-foot">
    <div class="copyright">
      <a href="https://github.com/shiyis/nlpwsys/tree/master"><b> This page is hosted on <img class="github-logo" src="https://unpkg.com/ionicons@5.1.2/dist/svg/logo-github.svg"></img></b></a></br>
       ©️ Last modified: May 09, 2024. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
    </div>
  </div>
  </div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/contrib/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
  </body>
</html>
